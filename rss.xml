<?xml version="1.0" encoding="UTF-8"?><rss version="2.0"><channel><title>NovaSky</title><description>NovaSky @ Berkeley Sky Computing Lab</description><link>https://novasky-ai.github.io/</link><language>en-US</language><item><title>Evolving SkyRL into a Highly-Modular RL Framework</title><link>https://novasky-ai.github.io/posts/skyrl-v01/</link><guid isPermaLink="true">https://novasky-ai.github.io/posts/skyrl-v01/</guid><description>SkyRL-v0.1 is a modular, performant RL framework for training LLMs. SkyRL makes it easy to prototype new training algorithms, environments, and training execution plans â€” without compromising usability or speed.</description><pubDate>Thu, 26 Jun 2025 00:00:00 GMT</pubDate></item><item><title>SkyRL-SQL: Simple and Data Efficient Multi-Turn RL for Text2SQL</title><link>https://novasky-ai.github.io/posts/skyrl-sql/</link><guid isPermaLink="true">https://novasky-ai.github.io/posts/skyrl-sql/</guid><description>Recent advances in RL have turned LLMs into interactive agents capable of reasoning, exploring, and executing actions. While tasks like math, web search, kernel code generation have seen progress, database interaction remains under-explored. We are excited to release SkyRL-SQL, a simple and data-efficient multi-turn RL training pipeline for text-to-SQL task. Using just 653 training samples, our trained model SkyRL-SQL-7B can improve accuracy by up to 8.7% compared to the base model, outperforming GPT-4o, o4-mini, and open-source SFT model trained on 2.5 million samples.</description><pubDate>Tue, 20 May 2025 00:00:00 GMT</pubDate></item><item><title>SkyRL-v0: Train Real-World Long-Horizon Agents via Reinforcement Learning</title><link>https://novasky-ai.github.io/posts/skyrl-v0/</link><guid isPermaLink="true">https://novasky-ai.github.io/posts/skyrl-v0/</guid><description>Most existing RL frameworks are optimized for tasks that involve stateless interactions over short horizons, such as search-augmented reasoning or simple code execution. In contrast, real-world tasks, like those represented in SWE-Bench, benefit from long-horizon planning in stateful, dynamic environments. This presents new challenges in both infrastructure and training algorithms. We introduce **SkyRL**, the first open-source online RL training framework for multi-turn tool use LLMs, optimized for long-horizon, real-environment tasks like SWE-Bench. Using SkyRL, we are able to achieve promising results on SWE-Bench-Verified across model lines!</description><pubDate>Wed, 07 May 2025 00:00:00 GMT</pubDate></item></channel></rss>